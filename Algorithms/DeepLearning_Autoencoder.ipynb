{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMPsMclu1cD0",
        "colab_type": "text"
      },
      "source": [
        "### Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NW7PjULhGt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcJDer3WhZVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/M2/DeepLearning\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(path)\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDUE3eJpjoEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Dataset\n",
        "#################################################\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "\n",
        "\n",
        "import mnist_reader\n",
        "X_train, y_train = mnist_reader.load_mnist(path+'/Datasets', kind='train')\n",
        "X_test, y_test = mnist_reader.load_mnist(path+'/Datasets', kind='t10k')\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "X_train, X_test, train_images, test_images = X_train / 255.0, X_test / 255.0, train_images / 255.0, test_images / 255.0\n",
        "#X_train, X_test, train_images, test_images = X_train / 127.5 - 1, X_test / 127.5 - 1, train_images / 127.5 - 1, test_images / 127.5 - 1\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Functions\n",
        "#################################################\n",
        "num_examples_to_generate=16\n",
        "def save_images(predictions, epoch):\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 255.0, cmap='gray')\n",
        "      #plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  #plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  save_images(predictions, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liFWbx7orbkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
        "\n",
        "nmi = normalized_mutual_info_score\n",
        "ari = adjusted_rand_score\n",
        "\n",
        "kmeans = KMeans(n_clusters=10, n_init=20)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "print(nmi(kmeans.labels_, y_train))\n",
        "print(ari(kmeans.labels_, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m913TteujpvI",
        "colab_type": "text"
      },
      "source": [
        "### **1. Deep Autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t4xn_WDhH6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
        "from scipy import io, sparse\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from statistics import mean, stdev\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "nmi = normalized_mutual_info_score\n",
        "ari = adjusted_rand_score\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Hyper-parameters\n",
        "#################################################\n",
        "epoch = 100\n",
        "batch_size = 256\n",
        "\n",
        "encoding_dim = 7*7\n",
        "hidden_dim = 256\n",
        "\n",
        "#activation='elu'\n",
        "activation='leaky_relu'\n",
        "optimizer='adam'\n",
        "#loss='mean_squared_error'\n",
        "loss='binary_crossentropy'\n",
        "#################################################\n",
        "\n",
        "out_activation = 'sigmoid' if loss=='binary_crossentropy' else 'linear'\n",
        "activation = None if activation=='leaky_relu' else activation\n",
        "\n",
        "#################################################\n",
        "# Auto-encoder\n",
        "#################################################\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "\n",
        "####### Encoder #######\n",
        "#   Layer\n",
        "encoded = Dense(hidden_dim, activation=activation)(input_img)\n",
        "if activation is None: encoded = layers.LeakyReLU()(encoded)\n",
        "\n",
        "#   Layer\n",
        "\"\"\"encoded = Dense(hidden_dim//4, activation=activation)(encoded)\n",
        "if activation is None: encoded = layers.LeakyReLU()(encoded)\"\"\"\n",
        "\n",
        "#   Layer\n",
        "encoded = Dense(encoding_dim, activation=out_activation)(encoded)\n",
        "\n",
        "\n",
        "####### Decoder #######\n",
        "decoded = encoded\n",
        "#   Layer\n",
        "\"\"\"decoded = Dense(hidden_dim//4, activation=activation)(decoded)\n",
        "if activation is None: decoded = layers.LeakyReLU()(decoded)\"\"\"\n",
        "\n",
        "#   Layer\n",
        "decoded = Dense(hidden_dim, activation=activation)(decoded)\n",
        "if activation is None: decoded = layers.LeakyReLU()(decoded)\n",
        "\n",
        "#   Layer\n",
        "decoded = Dense(784, activation=out_activation)(decoded)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "res_file_name = path+\"/ae_res_\"+str(encoding_dim)+\".txt\"\n",
        "\n",
        "best_nmi, best_ari = 0, 0 \n",
        "# Get old results\n",
        "if os.path.exists(res_file_name):\n",
        "    df = pd.read_csv(res_file_name, header=None)\n",
        "    best_nmi, best_ari = df.iloc[:,0].max(), df.iloc[:,1].max()\n",
        "    print(best_nmi, \" _ \", best_ari)\n",
        "\n",
        "nmis, aris = [], []\n",
        "for _ in range(20):\n",
        "\n",
        "    ####### Make model #######\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "    autoencoder.summary()\n",
        "\n",
        "    ####### Train #######\n",
        "    history = autoencoder.fit(X_train, X_train,\n",
        "                    epochs=epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_test, X_test))\n",
        "\n",
        "    ####### Encode images #######\n",
        "    encoder = Model(input_img, encoded)\n",
        "    encoded_images = encoder.predict(X_train)\n",
        "    print(encoded_images)\n",
        "    #################################################\n",
        "\n",
        "\n",
        "\n",
        "    #################################################\n",
        "    # KMeans\n",
        "    #################################################\n",
        "    print(\"run KMeans\")\n",
        "    kmeans = KMeans(n_clusters=10, n_init=20)\n",
        "    kmeans.fit(encoded_images)\n",
        "\n",
        "    res_nmi, res_ari = nmi(kmeans.labels_, y_train), ari(kmeans.labels_, y_train)\n",
        "    nmis.append(res_nmi)\n",
        "    aris.append(res_ari)\n",
        "    print(res_nmi)\n",
        "    print(res_ari)\n",
        "    #################################################\n",
        "\n",
        "    if mean([res_nmi, res_ari]) > mean([best_nmi, best_ari]):\n",
        "        best_nmi, best_ari = res_nmi, res_ari\n",
        "\n",
        "        ####### Plot and Save #######\n",
        "        t = np.arange(0, epoch)\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(t, history.history[\"loss\"], label='Train loss')\n",
        "        ax.plot(t, history.history[\"val_loss\"], label='Test loss')\n",
        "        legend = ax.legend(loc='upper right', shadow=True)\n",
        "        ax.set(xlabel='epoch', ylabel='loss')\n",
        "        ax.grid()\n",
        "        plt.savefig(path+\"/ae_loss_\"+str(encoding_dim)+\".svg\", format=\"svg\")\n",
        "        plt.show()\n",
        "\n",
        "        ####### Save encoding #######\n",
        "        io.savemat(path+\"/ae_encoded_\"+str(encoding_dim)+\".mat\", {'X' : sparse.csr_matrix(encoded_images)})\n",
        "\n",
        "    res_file = open(res_file_name, \"a\")\n",
        "    towrite = str(res_nmi) + \", \" + str(res_ari) + \"\\n\"\n",
        "    res_file.write(towrite)\n",
        "    res_file.close()        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJll9Pazj4dD",
        "colab_type": "text"
      },
      "source": [
        "## **2. Deep Convolutional Autoencoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pjWP6FRuSwF",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5_qJyYio4CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, layers, models\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
        "from math import sqrt\n",
        "\n",
        "nmi = normalized_mutual_info_score\n",
        "ari = adjusted_rand_score\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Hyper-parameters\n",
        "#################################################\n",
        "epoch = 10\n",
        "batch_size = 256\n",
        "\n",
        "encoding_dim = 7*7\n",
        "\n",
        "#activation='relu'\n",
        "activation='leaky_relu'\n",
        "optimizer='adam'\n",
        "#loss='mean_squared_error'\n",
        "loss='binary_crossentropy'\n",
        "num_conv=3\n",
        "\n",
        "use_batch_norm_encoded = False\n",
        "use_batch_norm_decoded = False\n",
        "#################################################\n",
        "\n",
        "encoding_size = int(sqrt(encoding_dim))\n",
        "out_activation = 'sigmoid' if loss=='binary_crossentropy' else 'linear'\n",
        "activation = None if activation=='leaky_relu' else activation\n",
        "\n",
        "def conv_layer(input_tensor, filters=32, kernel=(3,3), strides=1, \n",
        "               activation=\"relu\", use_batch_norm=False, padding='valid'):\n",
        "  out = layers.Conv2D(filters, kernel, strides=strides, activation=activation, padding=padding)(input_tensor)\n",
        "  if use_batch_norm:     out = layers.BatchNormalization()(out)\n",
        "  if activation is None: out = layers.LeakyReLU()(out)\n",
        "  return out\n",
        "\n",
        "def deconv_layer(input_tensor, filters=32, kernel=(3,3), strides=1, \n",
        "                 activation=\"relu\", use_batch_norm=False, padding='valid'):\n",
        "  out = layers.Conv2DTranspose(filters, kernel, strides=strides, activation=activation, padding=padding)(input_tensor)\n",
        "  if use_batch_norm:     out = layers.BatchNormalization()(out)\n",
        "  if activation is None: out = layers.LeakyReLU()(out)\n",
        "  return out\n",
        "\n",
        "def make_conv_autoencoder_model():\n",
        "  #################################################\n",
        "  # Convolutional Auto-encoder\n",
        "  #################################################\n",
        "  input_img = Input((28, 28, 1))\n",
        "\n",
        "  ####### Encoder #######\n",
        "  encoded = input_img\n",
        "  #   Layer\n",
        "  for _ in range(num_conv):\n",
        "      encoded = conv_layer(encoded, filters=32, kernel=(3,3), strides=1, \n",
        "                          activation=activation, use_batch_norm=use_batch_norm_encoded,\n",
        "                          padding='same')\n",
        "  encoded = layers.MaxPooling2D((2, 2))(encoded)\n",
        "\n",
        "  #   Layer\n",
        "  for _ in range(num_conv):\n",
        "      encoded = conv_layer(encoded, filters=64, kernel=(3,3), strides=1, \n",
        "                          activation=activation, use_batch_norm=use_batch_norm_encoded,\n",
        "                          padding='same')\n",
        "  encoded = layers.MaxPooling2D((2, 2))(encoded)\n",
        "\n",
        "  #   Layer\n",
        "  for _ in range(num_conv-1):\n",
        "      encoded = conv_layer(encoded, filters=64, kernel=(3,3), strides=1, \n",
        "                          activation=activation, use_batch_norm=use_batch_norm_encoded,\n",
        "                          padding='same')\n",
        "  encoded = conv_layer(encoded, filters=64, kernel=(3,3), strides=1, \n",
        "                      activation=activation, use_batch_norm=use_batch_norm_encoded)\n",
        "\n",
        "  #   Layer\n",
        "  encoded = layers.Flatten()(encoded)\n",
        "  encoded = layers.Dense(encoding_dim, activation=out_activation)(encoded)\n",
        "\n",
        "  ####### Decoder #######\n",
        "  decoded_input = encoded if encoding_size == 7 else layers.Dense(7*7)(encoded)\n",
        "  decoded = layers.Reshape((7,7,1))(decoded_input)\n",
        "\n",
        "  #   Layer\n",
        "  decoded = deconv_layer(decoded, filters=128, kernel=(3,3), strides=2, \n",
        "                         activation=activation, use_batch_norm=use_batch_norm_decoded,\n",
        "                         padding='same')\n",
        "  for _ in range(num_conv-1):\n",
        "      decoded = deconv_layer(decoded, filters=128, kernel=(3,3), strides=1, \n",
        "                          activation=activation, use_batch_norm=use_batch_norm_decoded,\n",
        "                          padding='same')\n",
        "\n",
        "  #   Layer\n",
        "  decoded = deconv_layer(decoded, filters=64, kernel=(3,3), strides=2, \n",
        "                         activation=activation, use_batch_norm=use_batch_norm_decoded,\n",
        "                         padding='same')  \n",
        "  for _ in range(num_conv-1):\n",
        "      decoded = deconv_layer(decoded, filters=64, kernel=(3,3), strides=1, \n",
        "                          activation=activation, use_batch_norm=use_batch_norm_decoded,\n",
        "                          padding='same')\n",
        "\n",
        "  #   Layer\n",
        "  for _ in range(num_conv):\n",
        "      decoded = deconv_layer(decoded, filters=32, kernel=(3,3), strides=1, \n",
        "                            activation=activation, use_batch_norm=use_batch_norm_decoded,\n",
        "                            padding='same')\n",
        "\n",
        "  #   Layer\n",
        "  decoded = layers.Conv2D(1, (3, 3), activation=out_activation, padding='same')(decoded)\n",
        "\n",
        "\n",
        "  ####### Make model #######\n",
        "  autoencoder = models.Model(input_img, decoded)\n",
        "  encoder = models.Model(input_img, encoded)\n",
        "  #decoder = models.Model(encoded, decoded)\n",
        "\n",
        "  return autoencoder, encoder, decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7PX9eVuqqI",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqLpAQewhml1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 20\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from scipy import io, sparse\n",
        "from statistics import mean, stdev\n",
        "\n",
        "best_nmi, best_ari = 0, 0\n",
        "nmis, aris = [], []\n",
        "\n",
        "for _ in range(20):\n",
        "    autoencoder, encoder, decoded = make_conv_autoencoder_model()\n",
        "    autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "    autoencoder.summary()\n",
        "\n",
        "    \"\"\"ae_checkpoint_dir = path+'/ae_training_checkpoints'\n",
        "    ae_checkpoint_prefix = os.path.join(ae_checkpoint_dir, \"ckpt\")\n",
        "    ae_checkpoint = tf.train.Checkpoint(autoencoder=autoencoder)\n",
        "\n",
        "    ae_checkpoint.restore(tf.train.latest_checkpoint(ae_checkpoint_dir))\"\"\"\n",
        "\n",
        "    for _ in range(8):\n",
        "        generate_and_save_images(autoencoder, 0, \n",
        "                              test_input=train_images[np.random.randint(low=0,high=train_images.shape[0],size=16)])\n",
        "\n",
        "    ####### Train #######\n",
        "    autoencoder.fit(train_images, train_images,\n",
        "                  epochs=epoch,\n",
        "                  batch_size=batch_size,\n",
        "                  shuffle=True,\n",
        "                  validation_data=(test_images, test_images))\n",
        "\n",
        "    #ae_checkpoint.save(file_prefix = ae_checkpoint_prefix)\n",
        "\n",
        "    for _ in range(8):\n",
        "        generate_and_save_images(autoencoder, 0, \n",
        "                          test_input=train_images[np.random.randint(low=0,high=train_images.shape[0],size=16)])\n",
        "    #################################################\n",
        "\n",
        "\n",
        "\n",
        "    #################################################\n",
        "    # KMeans\n",
        "    #################################################\n",
        "    ####### Encode images #######\n",
        "    encoded_images = encoder.predict(train_images)\n",
        "    print(encoded_images.shape)\n",
        "\n",
        "    ####### KMeans #######\n",
        "    print(\"run KMeans\")\n",
        "    kmeans = KMeans(n_clusters=10, n_init=20)\n",
        "    kmeans.fit(encoded_images)\n",
        "\n",
        "    res_nmi, res_ari = nmi(kmeans.labels_, y_train), ari(kmeans.labels_, y_train)\n",
        "    nmis.append(res_nmi)\n",
        "    aris.append(res_ari)\n",
        "    print(res_nmi)\n",
        "    print(res_ari)\n",
        "    #################################################\n",
        "\n",
        "    \"\"\"if mean([res_nmi, res_ari]) > mean([best_nmi, best_ari]):\n",
        "        best_nmi, best_ari = res_nmi, res_ari\n",
        "\n",
        "        ####### Save encoding #######\n",
        "        io.savemat(path+\"/cae_encoded.mat\", {'X' : sparse.csr_matrix(encoded_images)})\n",
        "\n",
        "    res_file = open(path+\"/cae_res.txt\", \"a\")\n",
        "    towrite = str(res_nmi) + \", \" + str(res_ari) + \"\\n\"\n",
        "    res_file.write(towrite)\n",
        "    res_file.close()\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"# Reconstruct one image per class\n",
        "index = [2, 17, 6, 4, 20, 9, 19, 7, 24, 1]\n",
        "to_predict = train_images[index]\n",
        "predictions = autoencoder.predict(to_predict)    \n",
        "\n",
        "for i in range(predictions.shape[0]):\n",
        "    #fig = plt.figure(figsize=(1,2))\n",
        "    #plt.subplot(1, 2, 1)\n",
        "    plt.imshow(predictions[i, :, :, 0] * 255.0, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(path+'/image{:d}.svg'.format(i), format=\"svg\")\n",
        "    #plt.subplot(1, 2, 2)\n",
        "    plt.imshow(to_predict[i, :, :, 0] * 255.0, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(path+'/image{:d}_original.svg'.format(i), format=\"svg\")\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48eGo9LwkAI0",
        "colab_type": "text"
      },
      "source": [
        "## **3. Deep Convolutional Adversarial Autoencoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ7FWjUHumkT",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn3uItqgoklx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras import layers, models, Input\n",
        "import numpy as np\n",
        "from statistics import mean\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Hyper-parameters\n",
        "#################################################\n",
        "batch_size = 256\n",
        "\n",
        "epoch = 100\n",
        "noise_dim = 100\n",
        "\n",
        "n_filter = 128\n",
        "#################################################\n",
        "\n",
        "\n",
        "\n",
        "def make_optimizer():\n",
        "  return tf.keras.optimizers.Adam(1e-4)  \n",
        "\n",
        "#################################################\n",
        "# Generator\n",
        "#################################################\n",
        "def make_generator_model(input_size=100):\n",
        "    input_img = Input((input_size, ))\n",
        "    layer = layers.Dense(7*7*n_filter, use_bias=False)(input_img)\n",
        "    layer = layers.BatchNormalization()(layer)\n",
        "    layer = layers.LeakyReLU()(layer)\n",
        "\n",
        "    layer = layers.Reshape((7, 7, n_filter))(layer)\n",
        "    #assert model.output_shape == (None, 7, 7, n_filter) # Note: None is the batch size\n",
        "\n",
        "    \"\"\"layer = layers.Conv2DTranspose(n_filter, (5, 5), strides=(1, 1), padding='same', use_bias=False)(layer)\n",
        "    layer = layers.BatchNormalization()(layer)\n",
        "    layer = layers.LeakyReLU()(layer)\"\"\"\n",
        "\n",
        "    layer = layers.Conv2DTranspose(n_filter//2, (5, 5), strides=(1, 1), padding='same', use_bias=False)(layer)\n",
        "    #assert model.output_shape == (None, 7, 7, n_filter//2)(layer)\n",
        "    layer = layers.BatchNormalization()(layer)\n",
        "    layer = layers.LeakyReLU()(layer)\n",
        "\n",
        "    layer = layers.Conv2DTranspose(n_filter//4, (5, 5), strides=(2, 2), padding='same', use_bias=False)(layer)\n",
        "    #assert model.output_shape == (None, 14, 14, n_filter//4)(layer)\n",
        "    layer = layers.BatchNormalization()(layer)\n",
        "    layer = layers.LeakyReLU()(layer)\n",
        "\n",
        "    layer = layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='sigmoid')(layer)\n",
        "    #assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    model = models.Model(input_img, layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def make_generator_optimizer():\n",
        "    return make_optimizer()  \n",
        "#################################################\n",
        "\n",
        "\n",
        "def make_autoencoder_optimizer():\n",
        "  return make_optimizer()  \n",
        "\n",
        "def autoencoder_loss(real_output):\n",
        "  return cross_entropy(tf.ones_like(real_output), real_output)\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Discriminator\n",
        "#################################################\n",
        "def make_disc(input_img):\n",
        "    layer = layers.Conv2D(n_filter//4, (5, 5), strides=(2, 2), padding='same',)(input_img)\n",
        "    layer = layers.LeakyReLU()(layer)\n",
        "    #layer = layers.Dropout(0.3)(layer)\n",
        "\n",
        "    layer = layers.Conv2D(n_filter//2, (5, 5), strides=(2, 2), padding='same')(layer)\n",
        "    layer = layers.LeakyReLU()(layer)\n",
        "    #layer = layers.Dropout(0.3)(layer)\n",
        "\n",
        "    \"\"\"layer = layers.Conv2D(n_filter, (5, 5), strides=(1, 1), padding='same')(layer)\n",
        "    layer = layers.LeakyReLU()(layer)\n",
        "    #layer = layers.Dropout(0.3)(layer)\"\"\"\n",
        "\n",
        "    layer = layers.Flatten()(layer)\n",
        "    #layer = layers.Dense(256)(layer)    \n",
        "    layer = layers.Dense(128)(layer)\n",
        "    layer = layers.Dense(1)(layer)\n",
        "\n",
        "    model = models.Model(input_img, layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = Input((28, 28, 1))\n",
        "    return make_disc(input_img)\n",
        "\n",
        "def make_discriminator_optimizer():\n",
        "    return make_optimizer()  \n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "#################################################   \n",
        "\n",
        "def make_gan(generator, discriminator):\n",
        "\tmodel = models.Sequential()\n",
        "\t\n",
        "\tmodel.add(generator)\n",
        "\tmodel.add(discriminator)\n",
        "\t\n",
        "\topt = make_discriminator_optimizer()\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "def make_aae(autoencoder, discriminator):\n",
        "\tmodel = models.Sequential()\n",
        "\t\n",
        "\tmodel.add(autoencoder)\n",
        "\tmodel.add(discriminator)\n",
        "\t\n",
        "\topt = make_optimizer()\n",
        "\t#opt = tf.keras.optimizers.Adam(2e-4)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model  \n",
        "#################################################   \n",
        "\n",
        "\n",
        "def generate_images(batch_size, noise_dim, generator):\n",
        "  noise = tf.random.normal([batch_size, noise_dim])\n",
        "  generated_images = generator(noise, training=True)\n",
        "  return generated_images\n",
        "#################################################  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxUkWpZ9AGru",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCwbP9WwkGUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 100\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "discriminator = make_discriminator_model()\n",
        "discriminator.summary()\n",
        "discriminator_optimizer = make_discriminator_optimizer()\n",
        "\n",
        "generator = make_generator_model()\n",
        "generator.summary()\n",
        "generator_optimizer =  make_generator_optimizer()\n",
        "\n",
        "gan_checkpoint_dir = path+'/gan_training_checkpoints'\n",
        "gan_checkpoint_prefix = os.path.join(gan_checkpoint_dir, \"ckpt\")\n",
        "gan_checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "#################################################    \n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def train(dataset):\n",
        "  gan_checkpoint.restore(tf.train.latest_checkpoint(gan_checkpoint_dir))\n",
        "  for ep in range(epoch):\n",
        "    print(\"epoch : \",ep, \" / \", epoch)\n",
        "    gen_losses, disc_losses = [], []\n",
        "    for it in range(int(dataset.shape[0] / batch_size)):\n",
        "      image_batch = dataset[np.random.randint(low=0,high=dataset.shape[0],size=batch_size)]\n",
        "      gen_loss, disc_loss = train_step(image_batch)\n",
        "      gen_losses.append(gen_loss.numpy())\n",
        "      disc_losses.append(disc_loss.numpy())\n",
        "\n",
        "    # Save the model\n",
        "    if (ep + 1) % 10 == 0:\n",
        "      print(\"checkpoint...\")\n",
        "      gan_checkpoint.save(file_prefix = gan_checkpoint_prefix)\n",
        "\n",
        "    generate_and_save_images(generator, ep, test_input=tf.random.normal([num_examples_to_generate, noise_dim]))\n",
        "\n",
        "    print(\"Generator loss     =\",mean(gen_losses), \"\\nDiscriminator loss =\",mean(disc_losses))\n",
        "\n",
        "#################################################    \n",
        "train(train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k_0PrLZAMtt",
        "colab_type": "text"
      },
      "source": [
        "### DCAA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF8CHNBmAEuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 50\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print(\"#################################################\\n# DISCRIMINATOR\\n#################################################\")\n",
        "discriminator = make_discriminator_model()\n",
        "#discriminator.compile(optimizer=make_discriminator_optimizer(), loss='binary_crossentropy')\n",
        "discriminator.summary()\n",
        "discriminator_optimizer = make_discriminator_optimizer()\n",
        "\n",
        "print(\"#################################################\\n#GENERATOR\\n#################################################\")\n",
        "generator = make_generator_model()\n",
        "generator.summary()\n",
        "generator_optimizer =  make_generator_optimizer()\n",
        "\n",
        "print(\"#################################################\\n# AUTOENCODER\\n#################################################\")\n",
        "autoencoder, encoder, decoded = make_conv_autoencoder_model()\n",
        "autoencoder.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "autoencoder.summary()\n",
        "autoencoder_optimizer = make_autoencoder_optimizer()\n",
        "\n",
        "print(\"#################################################\\n# AAE\\n#################################################\")\n",
        "aae = make_aae(autoencoder, discriminator)\n",
        "aae.summary()\n",
        "\n",
        "\"\"\"print(\"#################################################\\n# GAN\\n#################################################\")\n",
        "gan = make_gan(generator, discriminator)\n",
        "gan.summary()\"\"\"\n",
        "\n",
        "\n",
        "gan_checkpoint_dir = path+'/gan_training_checkpoints'\n",
        "gan_checkpoint_prefix = os.path.join(gan_checkpoint_dir, \"ckpt\")\n",
        "gan_checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "ae_checkpoint_dir = path+'/ae_training_checkpoints'\n",
        "ae_checkpoint_prefix = os.path.join(ae_checkpoint_dir, \"ckpt\")\n",
        "ae_checkpoint = tf.train.Checkpoint(autoencoder=autoencoder)\n",
        "\n",
        "\n",
        "#################################################    \n",
        "@tf.function\n",
        "def train_step(images, train_gen=True):\n",
        "    noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    if train_gen:\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))          \n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def aae_train_step(images):\n",
        "    with tf.GradientTape() as ae_tape:\n",
        "      decoded_images = autoencoder(images, training=True)      \n",
        "      real_output = discriminator(decoded_images, training=True)\n",
        "      ae_loss = autoencoder_loss(real_output)\n",
        "\n",
        "    gradients_of_autoencoder = ae_tape.gradient(ae_loss, autoencoder.trainable_variables)    \n",
        "    autoencoder_optimizer.apply_gradients(zip(gradients_of_autoencoder, autoencoder.trainable_variables))\n",
        "\n",
        "    return ae_loss\n",
        "\n",
        "def train(dataset):\n",
        "\n",
        "  #gan_checkpoint.restore(tf.train.latest_checkpoint(gan_checkpoint_dir))\n",
        "  ae_checkpoint.restore(tf.train.latest_checkpoint(ae_checkpoint_dir))\n",
        "\n",
        "  generate_and_save_images(autoencoder, 0, \n",
        "                          test_input=dataset[np.random.randint(low=0,high=dataset.shape[0],size=num_examples_to_generate)])\n",
        "  generate_and_save_images(generator, 0,\n",
        "                            test_input=tf.random.normal([num_examples_to_generate, noise_dim]))\n",
        "\n",
        "  # Training pipeline\n",
        "  for ep in range(epoch):\n",
        "    print(\"epoch : \",ep, \" / \", epoch)\n",
        "    losses = {\"Autoencoder\":[],\"GAN\":[],\"AAE\":[],\"Generator\":[],\"Discriminator\":[]}\n",
        "\n",
        "    for it in range(int(dataset.shape[0] / batch_size)):\n",
        "      image_batch = dataset[np.random.randint(low=0,high=dataset.shape[0],size=batch_size)]\n",
        "\n",
        "      # Print current losses\n",
        "      if it % 50 == 0:\n",
        "        print(it,\"/ \",int(dataset.shape[0] / batch_size))\n",
        "        \"\"\"for name in losses:\n",
        "          if losses[name] != []:\n",
        "            print(name, \"loss =\", mean(losses[name]))\"\"\"\n",
        "\n",
        "      # GAN training\n",
        "      gen_loss, disc_loss = train_step(image_batch)\n",
        "      losses[\"Generator\"].append(gen_loss.numpy())\n",
        "      losses[\"Discriminator\"].append(disc_loss.numpy())\n",
        "\n",
        "      # AAE training (without discriminator training)\n",
        "      aae_loss = aae_train_step(image_batch)\n",
        "      losses[\"AAE\"].append(aae_loss.numpy())\n",
        "\n",
        "      # AAE training\n",
        "      \"\"\"history = aae.fit(image_batch, np.ones(batch_size),\n",
        "                epochs=1, verbose=0,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True)\n",
        "      losses[\"AAE\"].append(history.history['loss'][0])    \n",
        "      _, _ = train_step(image_batch, train_gen=False)  \"\"\"\n",
        "\n",
        "      # Autoencoder training\n",
        "      history = autoencoder.fit(image_batch, image_batch,\n",
        "                epochs=1, verbose=0,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True)#,\n",
        "                #validation_data=(test_images, test_images))\n",
        "      losses[\"Autoencoder\"].append(history.history['loss'][0])      \n",
        "\n",
        "    # Plot images\n",
        "    generate_and_save_images(autoencoder, -1*ep, \n",
        "                            test_input=dataset[np.random.randint(low=0,high=dataset.shape[0],size=num_examples_to_generate)])\n",
        "    generate_and_save_images(generator, ep,\n",
        "                             test_input=tf.random.normal([num_examples_to_generate, noise_dim]))\n",
        "\n",
        "    # Print results\n",
        "    results = autoencoder.evaluate(test_images, test_images, batch_size=batch_size)\n",
        "    print('Autoencoder validation:', results)    \n",
        "    for name in losses:\n",
        "        if losses[name] != []:\n",
        "          print(name, \"loss =\", mean(losses[name]))\n",
        "\n",
        "\n",
        "#################################################    \n",
        "train(train_images)\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "# KMeans\n",
        "#################################################\n",
        "####### Encode images #######\n",
        "encoded_images = encoder.predict(train_images)\n",
        "print(encoded_images.shape)\n",
        "\n",
        "####### KMeans #######\n",
        "print(\"run KMeans\")\n",
        "kmeans = KMeans(n_clusters=10, n_init=20)\n",
        "kmeans.fit(encoded_images)\n",
        "\n",
        "print(nmi(kmeans.labels_, train_labels))\n",
        "print(ari(kmeans.labels_, train_labels))\n",
        "#################################################\n",
        "\n",
        "io.savemat(path+\"/caae2_encoded.mat\", {'X' : sparse.csr_matrix(encoded_images)})\n",
        "\n",
        "\n",
        "\"\"\" \n",
        "# GAN training      \n",
        "history = gan.fit(tf.random.normal([batch_size, noise_dim]), np.ones(batch_size),\n",
        "          epochs=1, verbose=0,\n",
        "          batch_size=batch_size,\n",
        "          shuffle=True)\n",
        "losses[\"GAN\"].append(history.history['loss'][0])\n",
        "\n",
        "generated_images = generate_images(batch_size, noise_dim, generator)\n",
        "history = discriminator.fit(generated_images, np.zeros(batch_size),\n",
        "          epochs=1, verbose=0,\n",
        "          batch_size=batch_size,\n",
        "          shuffle=True)\n",
        "losses[\"Discriminator\"].append(history.history['loss'][0])\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFooJaqtEi3A",
        "colab_type": "text"
      },
      "source": [
        "### DCAA 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC5BiTPgOfhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 50\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy import io, sparse\n",
        "\n",
        "print(\"#################################################\\n# DISCRIMINATOR\\n#################################################\")\n",
        "discriminator = make_discriminator_model()\n",
        "#discriminator.compile(optimizer=make_discriminator_optimizer(), loss='binary_crossentropy')\n",
        "discriminator.summary()\n",
        "#discriminator_optimizer = make_discriminator_optimizer()\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "disc_lr = 1e-7\n",
        "\n",
        "\"\"\"print(\"#################################################\\n#GENERATOR\\n#################################################\")\n",
        "generator = make_generator_model()\n",
        "generator.summary()\"\"\"\n",
        "#generator_optimizer =  make_generator_optimizer()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4)\n",
        "#generator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "print(\"#################################################\\n# AUTOENCODER\\n#################################################\")\n",
        "autoencoder, encoder, decoded = make_conv_autoencoder_model()\n",
        "autoencoder.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "autoencoder.summary()\n",
        "autoencoder_optimizer = make_autoencoder_optimizer()\n",
        "\n",
        "\n",
        "\"\"\"gan_checkpoint_dir = path+'/gan_training_checkpoints'\n",
        "gan_checkpoint_prefix = os.path.join(gan_checkpoint_dir, \"ckpt\")\n",
        "gan_checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\"\"\"\n",
        "\n",
        "ae_checkpoint_dir = path+'/ae_training_checkpoints'\n",
        "ae_checkpoint_prefix = os.path.join(ae_checkpoint_dir, \"ckpt\")\n",
        "ae_checkpoint = tf.train.Checkpoint(autoencoder=autoencoder)\n",
        "\n",
        "\n",
        "#################################################    \n",
        "\n",
        "def train_step(images, train_gen=True):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = autoencoder(images, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    if train_gen:\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, autoencoder.trainable_variables)\n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, autoencoder.trainable_variables))          \n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "\n",
        "\n",
        "def train(dataset):\n",
        "\n",
        "  #gan_checkpoint.restore(tf.train.latest_checkpoint(gan_checkpoint_dir))\n",
        "  ae_checkpoint.restore(tf.train.latest_checkpoint(ae_checkpoint_dir))\n",
        "\n",
        "  generate_and_save_images(autoencoder, 0, \n",
        "                          test_input=dataset[np.random.randint(low=0,high=dataset.shape[0],size=num_examples_to_generate)])\n",
        "\n",
        "  disc_epoch = 3\n",
        "  for ep in range(disc_epoch):\n",
        "    print(\"epoch : \",ep, \" / \", disc_epoch)\n",
        "    losses = {\"Autoencoder\":[],\"GAN\":[],\"AAE\":[],\"Generator\":[],\"Discriminator\":[]}\n",
        "\n",
        "    for it in range(int(dataset.shape[0] / batch_size)):\n",
        "      image_batch = dataset[np.random.randint(low=0,high=dataset.shape[0],size=batch_size)]\n",
        "      # GAN pre-training\n",
        "      gen_loss, disc_loss = train_step(image_batch, train_gen=False)\n",
        "      losses[\"Discriminator\"].append(disc_loss.numpy())\n",
        "    print(mean(losses[\"Discriminator\"]))\n",
        "\n",
        "  global discriminator_optimizer      \n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(disc_lr)\n",
        "\n",
        "  # Training pipeline\n",
        "  for ep in range(epoch):\n",
        "    print(\"epoch : \",ep, \" / \", epoch)\n",
        "    losses = {\"Autoencoder\":[],\"GAN\":[],\"AAE\":[],\"Generator\":[],\"Discriminator\":[]}\n",
        "\n",
        "    for it in range(int(dataset.shape[0] / batch_size)):\n",
        "      image_batch = dataset[np.random.randint(low=0,high=dataset.shape[0],size=batch_size)]\n",
        "\n",
        "      # Print current losses\n",
        "      if it % 50 == 0:\n",
        "        print(it,\"/ \",int(dataset.shape[0] / batch_size))\n",
        "\n",
        "      # GAN training\n",
        "      gen_loss, disc_loss = train_step(image_batch)\n",
        "      losses[\"Generator\"].append(gen_loss.numpy())\n",
        "      losses[\"Discriminator\"].append(disc_loss.numpy())\n",
        "\n",
        "      # Autoencoder training\n",
        "      history = autoencoder.fit(image_batch, image_batch,\n",
        "                epochs=1, verbose=0,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True)#,\n",
        "                #validation_data=(test_images, test_images))\n",
        "      losses[\"Autoencoder\"].append(history.history['loss'][0])     \n",
        "\n",
        "    # Plot images\n",
        "    generate_and_save_images(autoencoder, -1*ep, \n",
        "                            test_input=dataset[np.random.randint(low=0,high=dataset.shape[0],size=num_examples_to_generate)])\n",
        "\n",
        "    # Print results\n",
        "    results = autoencoder.evaluate(test_images, test_images, batch_size=batch_size)\n",
        "    print('Autoencoder validation:', results)    \n",
        "    for name in losses:\n",
        "        if losses[name] != []:\n",
        "          print(name, \"loss =\", mean(losses[name]))\n",
        "\n",
        "\n",
        "#################################################    \n",
        "train(train_images)\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "# KMeans\n",
        "#################################################\n",
        "####### Encode images #######\n",
        "encoded_images = encoder.predict(train_images)\n",
        "print(encoded_images.shape)\n",
        "\n",
        "####### KMeans #######\n",
        "print(\"run KMeans\")\n",
        "kmeans = KMeans(n_clusters=10, n_init=20)\n",
        "kmeans.fit(encoded_images)\n",
        "\n",
        "print(nmi(kmeans.labels_, train_labels))\n",
        "print(ari(kmeans.labels_, train_labels))\n",
        "#################################################\n",
        "\n",
        "io.savemat(path+\"/caae2_encoded.mat\", {'X' : sparse.csr_matrix(encoded_images)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqHZssbXUYJp",
        "colab_type": "text"
      },
      "source": [
        "## **4. Ensemble Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8HtJEkvUgqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import io, sparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
        "\n",
        "nmi = normalized_mutual_info_score\n",
        "ari = adjusted_rand_score\n",
        "\n",
        "res_path = path+\"/Res/\"\n",
        "\n",
        "ae = io.loadmat(res_path+\"ae_49_encoded.mat\")['X'].todense()\n",
        "ae2 = io.loadmat(res_path+\"ae_encoded.mat\")['X'].todense()\n",
        "ae3 = io.loadmat(res_path+\"ae_100_encoded.mat\")['X'].todense()\n",
        "cae = io.loadmat(res_path+\"cae1_encoded.mat\")['X'].todense()\n",
        "cae2 = io.loadmat(res_path+\"cae2_encoded.mat\")['X'].todense()\n",
        "\n",
        "data = [ae, ae2, ae3, cae, cae2]\n",
        "\n",
        "all_data = np.hstack([ae, ae2, ae3, cae, cae2])\n",
        "print(all_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-nSLGlccbF8",
        "colab_type": "text"
      },
      "source": [
        "### Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKES_Yejb_HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################\n",
        "# Ensemble\n",
        "#####################\n",
        "\n",
        "for _ in range(10):\n",
        "  kmeans = KMeans(n_clusters=10, n_init=20)\n",
        "  kmeans.fit(all_data)\n",
        "\n",
        "  print(nmi(kmeans.labels_, y_train))\n",
        "  print(ari(kmeans.labels_, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcY5czRUcdZY",
        "colab_type": "text"
      },
      "source": [
        "### Consensus co-assoc and hypergraph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYwb6jH0cYae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+git://github.com/GGiecold/Cluster_Ensembles.git\n",
        "!apt-get install metis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-hVbZQ8ck3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statistics import mean, stdev\n",
        "import numpy as np\n",
        "#import Cluster_Ensembles as CE\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "\n",
        "nmi, ari = normalized_mutual_info_score, adjusted_rand_score\n",
        "\n",
        "#################################################\n",
        "# Functions\n",
        "#################################################\n",
        "def make_co_assoc(row_labels):\n",
        "    co_assoc = np.zeros((row_labels.shape[1], row_labels.shape[1]))\n",
        "    for i in range(row_labels.shape[0]):\n",
        "        labels = row_labels[i,]\n",
        "        #temp = np.array([[int(i == j) for i in labels] for j in labels])\n",
        "        n_values = np.max(labels) + 1\n",
        "        temp = np.eye(n_values)[labels]\n",
        "        temp = np.dot(temp, temp.T)\n",
        "        co_assoc += temp\n",
        "    return co_assoc\n",
        "\n",
        "\n",
        "def make_co_assoc_sparse(row_labels):\n",
        "    co_assoc = sparse.csr_matrix((row_labels.shape[1], row_labels.shape[1]))\n",
        "    for i in range(row_labels.shape[0]):\n",
        "        labels = row_labels[i,]\n",
        "        n_values = np.max(labels) + 1\n",
        "        temp = sparse.csr_matrix((np.ones(labels.shape), (np.arange(labels.shape[0]), labels)))\n",
        "        temp = temp.dot(temp.T)\n",
        "        co_assoc += temp\n",
        "    return co_assoc    \n",
        "\n",
        "\n",
        "def run_cluster_ensembles(row_labels, number_of_classes):\n",
        "    res = CE.cluster_ensembles(cluster_runs=row_labels, N_clusters_max=number_of_classes)\n",
        "    \n",
        "    return res\n",
        "\n",
        "    \n",
        "def run_co_assoc(row_labels, number_of_classes, use_sparse=False):\n",
        "    print(\"make co_assoc...\")\n",
        "    if use_sparse:\n",
        "        co_assoc = make_co_assoc_sparse(row_labels)\n",
        "    else:\n",
        "        co_assoc = make_co_assoc(row_labels)\n",
        "        \n",
        "    print(\"run kMeans...\")\n",
        "    verbose = 1 if use_sparse else 0\n",
        "    model = KMeans(n_clusters=number_of_classes, n_init=20, verbose=verbose)    \n",
        "    model.fit(co_assoc)\n",
        "\n",
        "    return model.labels_\n",
        "#################################################\n",
        "\n",
        "\n",
        "t_row_labels = []\n",
        "it = 5\n",
        "file_name = path+\"/Res/partitions_\"+str(it)+\".csv\"\n",
        "\n",
        "\"\"\"for dataset in data:\n",
        "    print(\"==============\")\n",
        "    for i in range(it):\n",
        "        print(i)\n",
        "        model = KMeans(n_clusters=10, n_init=20)\n",
        "        model.fit(dataset)\n",
        "        t_row_labels.append(model.labels_)\n",
        "        row_labels = np.array(t_row_labels).T\n",
        "\n",
        "row_labels = np.array(t_row_labels).T\n",
        "print(row_labels.shape)\n",
        "pd.DataFrame(row_labels).to_csv(file_name, index=False)\"\"\"\n",
        "\n",
        "t_row_labels = np.array(pd.read_csv(file_name).T)\n",
        "t_y_train = y_train\n",
        "\n",
        "for _ in range(20):\n",
        "    indexes = []\n",
        "\n",
        "    for yi in np.unique(y_train):\n",
        "        t_indexes = np.arange(y_train.shape[0])[y_train == yi]\n",
        "        indexes.append(t_indexes[np.random.randint(low=0, high=t_indexes.shape[0], size=2000)])\n",
        "\n",
        "    indexes = np.array(indexes).ravel()\n",
        "    row_labels = t_row_labels[:,indexes]\n",
        "    y_train = t_y_train[indexes]\n",
        "\n",
        "    print(row_labels.shape)\n",
        "    print(y_train.shape)\n",
        "\n",
        "    res = run_co_assoc(row_labels, 10)\n",
        "    #res = run_cluster_ensembles(row_labels, 10)\n",
        "    \"\"\"model = KMeans(n_clusters=10, n_init=20)    \n",
        "    model.fit(row_labels.T)\n",
        "    res = model.labels_\"\"\"\n",
        "\n",
        "    print(nmi(res, y_train.ravel()), \", \", ari(res, y_train.ravel()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}